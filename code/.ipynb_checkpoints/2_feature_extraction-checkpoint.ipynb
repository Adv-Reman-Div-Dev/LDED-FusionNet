{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791f2627-ee73-4e0a-be02-f2aca1267016",
   "metadata": {},
   "source": [
    "# LDED Audiovisual Fusion \n",
    "\n",
    "Author: Chen Lequn.\n",
    "Created on 13 Sep 2023.\n",
    "\n",
    "- Materialï¼š Maraging Steel 300\n",
    "- Process: Robotic Llser-directed energy deposition\n",
    "- Recorded data: position, veolocity, coaxial ccd features, acoustic feature\n",
    "- Quality labels generated: keyhole pores, cracks, defect-free\n",
    "\n",
    "### Notebook 2: Feature extraction\n",
    "- Extract handcrafted features from video and audio stream\n",
    "- Vision features: melt pool geometric features, including width, length, moment of area, convex hull, etc.\n",
    "- Audio features: spectral centroid, spectral bandwidth, flux, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44abb3f3-6292-413e-b442-07d572d373db",
   "metadata": {},
   "source": [
    "### System setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "200b9ea2-6492-49ae-8c3e-8325602e4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import essentia.standard as es\n",
    "\n",
    "\n",
    "import os\n",
    "# Scikit learn\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle, resample, class_weight\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "## plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd4c469f-a5fa-499a-8779-0e3fb3953442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_directories(base_path, sample_numbers):\n",
    "    sample_directories = []\n",
    "    for sample_number in sample_numbers:\n",
    "        sample_directories.append(os.path.join(base_path, f'segmented_25Hz/{sample_number}'))\n",
    "    return sample_directories\n",
    "\n",
    "Multimodal_dataset_PATH = \"/home/chenlequn/Dataset/LDED_acoustic_visual_monitoring_dataset\"\n",
    "# samples = [21, 22, 23, 26]\n",
    "samples = [21]\n",
    "sample_directories = get_sample_directories(Multimodal_dataset_PATH, samples)\n",
    "\n",
    "# Get lists of image and audio directories for each sample\n",
    "image_directories = [os.path.join(sample_dir, 'images') for sample_dir in sample_directories]\n",
    "audio_directories = [os.path.join(sample_dir, 'denoised_audio') for sample_dir in sample_directories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3596831-f611-4595-8aa8-f413451e840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT_DIR = \"../\"\n",
    "IMAGE_PATH = os.path.join(PROJECT_ROOT_DIR, \"result_images\", 'feature_extraction')\n",
    "os.makedirs(IMAGE_PATH, exist_ok=True)\n",
    "\n",
    "## function for automatically save the diagram/graph into the folder \n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGE_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "plt.rcParams[\"axes.linewidth\"] = 2.50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8917736c-bd39-46b2-8a24-c36ab02e38d7",
   "metadata": {},
   "source": [
    "## Extracting melt pool visual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d361ee1-0bfd-4038-8c39-5f1c9871e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_contour_extraction(image, threshold=100):\n",
    "    \"\"\"\n",
    "    Extract general contour features from a given image.\n",
    "    \n",
    "    Parameters:\n",
    "        image (ndarray): The input image.\n",
    "        threshold (int): The threshold value for image processing.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted features.\n",
    "    \"\"\"\n",
    "    # Initialize the result dictionary with zeros\n",
    "    result = {\n",
    "        'max_contour_area': 0,\n",
    "        'rectangle_angle': 0,\n",
    "        'rectangle_width': 0,\n",
    "        'rectangle_height': 0,\n",
    "        'ellipse_angle': 0,\n",
    "        'ellipse_width': 0,\n",
    "        'ellipse_height': 0\n",
    "    }\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    src_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply blur\n",
    "    src_gray = cv2.blur(src_gray, (3, 3))\n",
    "    \n",
    "    # Apply threshold\n",
    "    _, threshold_output = cv2.threshold(src_gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(threshold_output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if not contours:\n",
    "        return result  # Return result with zeros if no contours are found\n",
    "    \n",
    "    # Find the rotated rectangles and ellipses for each contour\n",
    "    min_rects = [cv2.minAreaRect(np.array(contour)) for contour in contours]\n",
    "    contour_areas = [cv2.contourArea(np.array(contour)) for contour in contours]\n",
    "    \n",
    "    # Get the index of the max contour area\n",
    "    max_contour_area_index = np.argmax(contour_areas)\n",
    "    max_contour_area = contour_areas[max_contour_area_index]\n",
    "    \n",
    "    # Store the max contour area\n",
    "    result['max_contour_area'] = max_contour_area\n",
    "    \n",
    "    # Store rectangle features\n",
    "    rect = min_rects[max_contour_area_index]\n",
    "    result['rectangle_angle'] = rect[-1]\n",
    "    result['rectangle_width'] = rect[1][0]\n",
    "    result['rectangle_height'] = rect[1][1]\n",
    "    \n",
    "    # Store ellipse features if enough points for fitEllipse\n",
    "    if len(contours[max_contour_area_index]) > 5:\n",
    "        ellipse = cv2.fitEllipse(np.array(contours[max_contour_area_index]))\n",
    "        result['ellipse_angle'] = ellipse[-1]\n",
    "        result['ellipse_width'] = ellipse[1][0]\n",
    "        result['ellipse_height'] = ellipse[1][1]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a9c382b-5b0d-4b85-b371-d930b1f7e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convex_hull_extract(frame, threshold=100):\n",
    "    \"\"\"\n",
    "    Extract convex hull features from a given image.\n",
    "    \n",
    "    Parameters:\n",
    "        image_path (str): The path to the image file.\n",
    "        threshold (int): The threshold value for binary conversion.\n",
    "    \n",
    "    Returns:\n",
    "        max_hull_area (float): The maximum area among all convex hulls.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to grayscale if the image is colored\n",
    "    if frame.shape[-1] > 1:\n",
    "        src_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        src_gray = frame\n",
    "\n",
    "    # Blur the image\n",
    "    src_gray = cv2.blur(src_gray, (3, 3))\n",
    "    \n",
    "    # Apply threshold\n",
    "    ret, threshold_output = cv2.threshold(src_gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(threshold_output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Initialize return values\n",
    "    max_hull_area = 0.0\n",
    "\n",
    "    # Check if any contour is detected\n",
    "    if contours:\n",
    "        # Find the convex hull object for each contour\n",
    "        hull = [cv2.convexHull(cnt) for cnt in contours]\n",
    "        \n",
    "        # Find the bounding convex hull area for each contour\n",
    "        hull_area = [cv2.contourArea(h) for h in hull]\n",
    "        \n",
    "        # Get the maximum convex hull area\n",
    "        max_hull_area = max(hull_area)\n",
    "        \n",
    "#         # Draw contours and convex hull on the original image (for visualization)\n",
    "#         drawing = np.zeros((threshold_output.shape[0], threshold_output.shape[1], 3), dtype=np.uint8)\n",
    "#         for i in range(len(contours)):\n",
    "#             color = (np.random.randint(0,256), np.random.randint(0,256), np.random.randint(0,256))\n",
    "#             cv2.drawContours(drawing, contours, i, color)\n",
    "#             cv2.drawContours(drawing, hull, i, color, 2)\n",
    "        \n",
    "#         # Show the output image with contours and convex hull\n",
    "#         plt.imshow(cv2.cvtColor(drawing, cv2.COLOR_BGR2RGB))\n",
    "#         plt.title('Contours and Convex Hull')\n",
    "#         plt.axis('off')\n",
    "#         plt.show()\n",
    "        \n",
    "    return max_hull_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30cc1e9a-16bf-407e-bdfe-e3bf27e2f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction for moments\n",
    "def moment_extract(image, threshold):\n",
    "    # Initialize moments as zeros\n",
    "    features = {\n",
    "        'm00': 0,\n",
    "        'm10': 0,\n",
    "        'm01': 0,\n",
    "        'm20': 0,\n",
    "        'm11': 0,\n",
    "        'm02': 0,\n",
    "        'm30': 0,\n",
    "        'm21': 0,\n",
    "        'm12': 0,\n",
    "        'm03': 0,\n",
    "        'mu20': 0,\n",
    "        'mu11': 0,\n",
    "        'mu02': 0,\n",
    "        'mu30': 0,\n",
    "        'mu21': 0,\n",
    "        'mu12': 0,\n",
    "        'mu03': 0,\n",
    "        'nu20': 0,\n",
    "        'nu11': 0,\n",
    "        'nu02': 0,\n",
    "        'nu30': 0,\n",
    "        'nu21': 0,\n",
    "        'nu12': 0,\n",
    "        'nu03': 0,\n",
    "        'center_x': 0,\n",
    "        'center_y': 0,\n",
    "        'contour_area': 0,\n",
    "        'contour_length': 0\n",
    "    }\n",
    "    \n",
    "    # Convert to grayscale if the image is colored\n",
    "    if len(image.shape) > 2:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "\n",
    "    # Thresholding\n",
    "    _, thresh = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        moments = cv2.moments(largest_contour)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if moments['m00'] != 0:\n",
    "            for moment_name, moment_value in moments.items():\n",
    "                features[moment_name] = moment_value\n",
    "                \n",
    "            features['center_x'] = moments['m10'] / moments['m00']\n",
    "            features['center_y'] = moments['m01'] / moments['m00']\n",
    "            features['contour_area'] = cv2.contourArea(largest_contour)\n",
    "            features['contour_length'] = cv2.arcLength(largest_contour, True)\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b07648-fe82-4ca0-8299-aaaa3f686566",
   "metadata": {},
   "source": [
    "## Extract Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9be446-594f-48cc-860d-d5238571ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_time_domain_features(audio_signal, sample_rate=44100):\n",
    "    \"\"\"\n",
    "    Extract time domain features from an audio signal using Essentia.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_signal: numpy array, the audio signal from which to extract features\n",
    "    - sample_rate: int, the sample rate of the audio signal\n",
    "    \n",
    "    Returns:\n",
    "    - features: dict, a dictionary containing the extracted features\n",
    "    \"\"\"\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # RMS Energy\n",
    "    rms_algo = es.RMS()\n",
    "    rms_energy = rms_algo(audio_signal)\n",
    "    features['rms_energy'] = rms_energy\n",
    "    \n",
    "    # Amplitude Envelope\n",
    "    envelope_algo = es.Envelope()\n",
    "    amplitude_envelope = envelope_algo(audio_signal)\n",
    "    features['amplitude_envelope_mean'] = amplitude_envelope.mean()\n",
    "    features['amplitude_envelope_std'] = amplitude_envelope.std()\n",
    "    \n",
    "    # Zero Crossing Rate\n",
    "    zcr_algo = es.ZeroCrossingRate()\n",
    "    zero_crossing_rate = zcr_algo(audio_signal)\n",
    "    features['zero_crossing_rate'] = zero_crossing_rate\n",
    "    \n",
    "    # Dynamic Complexity and Loudness\n",
    "    dyn_algo = es.DynamicComplexity()\n",
    "    dynamic_complexity, loudness = dyn_algo(audio_signal)\n",
    "    features['dynamic_complexity'] = dynamic_complexity\n",
    "    features['loudness'] = loudness\n",
    "\n",
    "    # Loudness Vickers\n",
    "    loudness_algo = es.LoudnessVickers()\n",
    "    loudness_vickers = loudness_algo(audio_signal)\n",
    "    features['loudness_vickers'] = loudness_vickers\n",
    "\n",
    "    return features\n",
    "\n",
    "# Test the function with a sample audio signal\n",
    "import numpy as np\n",
    "sample_audio_signal = np.random.rand(44100)  # 1 second of random audio at 44.1 kHz\n",
    "\n",
    "features = extract_time_domain_features(sample_audio_signal)\n",
    "features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e38245c-5d82-461d-a33e-83a202e602de",
   "metadata": {},
   "source": [
    "# Extract all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "765b54d0-fe72-4fca-b1b9-a4430ceec504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/chenlequn/Dataset/LDED_acoustic_visual_monitoring_dataset/segmented_25Hz/21/images',\n",
       " '/home/chenlequn/Dataset/LDED_acoustic_visual_monitoring_dataset/segmented_25Hz/22/images',\n",
       " '/home/chenlequn/Dataset/LDED_acoustic_visual_monitoring_dataset/segmented_25Hz/23/images',\n",
       " '/home/chenlequn/Dataset/LDED_acoustic_visual_monitoring_dataset/segmented_25Hz/26/images']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1c29e01-d803-4f8c-af1c-7b344ea5b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(image_directories, threshold=100):\n",
    "    all_features_list = []\n",
    "    total_images = sum([len(os.listdir(img_dir)) for img_dir in image_directories if os.path.isdir(img_dir)])\n",
    "    pbar = tqdm(total=total_images, desc=\"Processing images\")\n",
    "\n",
    "    for img_dir in image_directories:\n",
    "        if os.path.isdir(img_dir):\n",
    "            for img_name in os.listdir(img_dir):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(img_dir, img_name)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    \n",
    "                    features_contour = general_contour_extraction(img, threshold=threshold)\n",
    "                    max_hull = convex_hull_extract(img, threshold=threshold)\n",
    "                    features_moments = moment_extract(img, threshold=threshold)\n",
    "                    \n",
    "                    # Merge all dictionaries into one\n",
    "                    merged_features = {'image_name': img_name, **features_contour, 'max_hull': max_hull, **features_moments}\n",
    "                    all_features_list.append(merged_features)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    return pd.DataFrame(all_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffe19aed-e8f4-4a13-b16a-c29926a3ef0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5143/5143 [00:25<00:00, 200.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>max_contour_area</th>\n",
       "      <th>rectangle_angle</th>\n",
       "      <th>rectangle_width</th>\n",
       "      <th>rectangle_height</th>\n",
       "      <th>ellipse_angle</th>\n",
       "      <th>ellipse_width</th>\n",
       "      <th>ellipse_height</th>\n",
       "      <th>max_hull</th>\n",
       "      <th>m00</th>\n",
       "      <th>...</th>\n",
       "      <th>nu11</th>\n",
       "      <th>nu02</th>\n",
       "      <th>nu30</th>\n",
       "      <th>nu21</th>\n",
       "      <th>nu12</th>\n",
       "      <th>nu03</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "      <th>contour_area</th>\n",
       "      <th>contour_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_21_2038.jpg</td>\n",
       "      <td>231979.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>479.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>2.577053</td>\n",
       "      <td>574.159973</td>\n",
       "      <td>818.167725</td>\n",
       "      <td>236628.0</td>\n",
       "      <td>232057.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006111</td>\n",
       "      <td>0.078487</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>-0.002744</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>247.358734</td>\n",
       "      <td>229.456223</td>\n",
       "      <td>232057.0</td>\n",
       "      <td>2326.891477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_21_2716.jpg</td>\n",
       "      <td>247762.5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>639.000000</td>\n",
       "      <td>81.376549</td>\n",
       "      <td>537.173401</td>\n",
       "      <td>825.702881</td>\n",
       "      <td>260181.0</td>\n",
       "      <td>247724.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007437</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>-0.003457</td>\n",
       "      <td>-0.001749</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>309.548025</td>\n",
       "      <td>195.965763</td>\n",
       "      <td>247724.0</td>\n",
       "      <td>2372.048770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_21_2351.jpg</td>\n",
       "      <td>214554.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>479.000000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>3.983349</td>\n",
       "      <td>522.245422</td>\n",
       "      <td>614.861877</td>\n",
       "      <td>219719.5</td>\n",
       "      <td>214637.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001850</td>\n",
       "      <td>0.081376</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.000970</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>234.949085</td>\n",
       "      <td>237.435629</td>\n",
       "      <td>214637.0</td>\n",
       "      <td>2272.714850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_21_1539.jpg</td>\n",
       "      <td>211149.5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>478.999939</td>\n",
       "      <td>483.999939</td>\n",
       "      <td>3.726851</td>\n",
       "      <td>513.294983</td>\n",
       "      <td>621.059265</td>\n",
       "      <td>215107.5</td>\n",
       "      <td>211283.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001874</td>\n",
       "      <td>0.083399</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>-0.000860</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>228.261650</td>\n",
       "      <td>234.260897</td>\n",
       "      <td>211283.0</td>\n",
       "      <td>2079.376759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_21_4902.jpg</td>\n",
       "      <td>258557.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>565.999878</td>\n",
       "      <td>478.999939</td>\n",
       "      <td>178.969452</td>\n",
       "      <td>587.517456</td>\n",
       "      <td>886.574585</td>\n",
       "      <td>263607.5</td>\n",
       "      <td>258438.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002776</td>\n",
       "      <td>0.072466</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>-0.000871</td>\n",
       "      <td>-0.000617</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>270.647355</td>\n",
       "      <td>236.184484</td>\n",
       "      <td>258438.0</td>\n",
       "      <td>2342.783832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_name  max_contour_area  rectangle_angle  rectangle_width  \\\n",
       "0  sample_21_2038.jpg          231979.0             90.0       479.000000   \n",
       "1  sample_21_2716.jpg          247762.5             90.0       451.000000   \n",
       "2  sample_21_2351.jpg          214554.0             90.0       479.000000   \n",
       "3  sample_21_1539.jpg          211149.5             90.0       478.999939   \n",
       "4  sample_21_4902.jpg          258557.5              0.0       565.999878   \n",
       "\n",
       "   rectangle_height  ellipse_angle  ellipse_width  ellipse_height  max_hull  \\\n",
       "0        528.000000       2.577053     574.159973      818.167725  236628.0   \n",
       "1        639.000000      81.376549     537.173401      825.702881  260181.0   \n",
       "2        501.000000       3.983349     522.245422      614.861877  219719.5   \n",
       "3        483.999939       3.726851     513.294983      621.059265  215107.5   \n",
       "4        478.999939     178.969452     587.517456      886.574585  263607.5   \n",
       "\n",
       "        m00  ...      nu11      nu02      nu30      nu21      nu12      nu03  \\\n",
       "0  232057.0  ... -0.006111  0.078487  0.000851 -0.002744 -0.000768  0.001435   \n",
       "1  247724.0  ... -0.007437  0.053936  0.004801 -0.003457 -0.001749  0.001352   \n",
       "2  214637.0  ... -0.001850  0.081376  0.000582 -0.000139 -0.000970 -0.000040   \n",
       "3  211283.0  ... -0.001874  0.083399  0.000717 -0.000860 -0.001375  0.000327   \n",
       "4  258438.0  ... -0.002776  0.072466  0.000320 -0.000871 -0.000617  0.000196   \n",
       "\n",
       "     center_x    center_y  contour_area  contour_length  \n",
       "0  247.358734  229.456223      232057.0     2326.891477  \n",
       "1  309.548025  195.965763      247724.0     2372.048770  \n",
       "2  234.949085  237.435629      214637.0     2272.714850  \n",
       "3  228.261650  234.260897      211283.0     2079.376759  \n",
       "4  270.647355  236.184484      258438.0     2342.783832  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_all_features(image_directories)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
