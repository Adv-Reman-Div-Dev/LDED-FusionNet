{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63e6a59-b6d6-4f30-8ac9-44442c681499",
   "metadata": {},
   "source": [
    "# LDED Audiovisual Fusion \n",
    "\n",
    "Author: Chen Lequn.\n",
    "Created on 13 Sep 2023.\n",
    "\n",
    "- Material: Maraging Steel 300\n",
    "- Process: Robotic Laser-directed energy deposition\n",
    "- Recorded data: position, veolocity, coaxial ccd features, audio feature\n",
    "- Quality labels generated: keyhole pores, cracks, defect-free\n",
    "\n",
    "### Notebook 4: ML modelling - baseline 1 (feature-based audio visual fusion model)\n",
    "- Using the handcrafted features from video and audio stream\n",
    "- Vision features: melt pool geometric features, including width, length, moment of area, convex hull, etc.\n",
    "- Audio features: spectral centroid, spectral bandwidth, flux, etc.\n",
    "- __Modelling__: Once the features are ready, they can be used to train a machine learning model.\n",
    "- __Evaluate__ the predictions of the validation data by calculating the f1 score and showing a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0f4407-e4ea-4a39-8f89-a6ef363c5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearnex import patch_sklearn, config_context\n",
    "# import dpctl\n",
    "# patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbebcc9-d371-4c3b-8dc6-0fe3573c50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import itertools\n",
    "from pandas import DataFrame\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import gca\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# For K Nearest Neighbours:\n",
    "from sklearn import neighbors\n",
    "# For support vector machine:\n",
    "from sklearn import svm\n",
    "# For Gaussian process:\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "# For neural network:\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# For decision tree:\n",
    "from sklearn import tree\n",
    "# For plotting the decision tree structure:\n",
    "# import graphviz\n",
    "import pickle\n",
    "# For ensemble methods: random forest ad AdaBoost\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "# For Naive Bayes method:\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# For logistic regression:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from scipy.interpolate import griddata\n",
    "from pylab import * # For adjusting frame width only\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sklearn.gaussian_process as gp \n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.utils import resample, class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "# Use grid search with cross validation to select ML model hyper-parameters:\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272566c7-1935-43be-8485-ad893248bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For ML model saving\n",
    "import pickle\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_theme(style=\"white\", palette=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e299b0-3671-4b36-b4d5-d1f8343b4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "plt.rcParams[\"axes.linewidth\"] = 2.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7860a5ee-3a01-4b33-bc9a-8fa40cde9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from utils import *\n",
    "import glob\n",
    "import os\n",
    "# import utils\n",
    "FRAME_SIZE = 2048\n",
    "HOP_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd1c773-79d6-4328-813d-1d8ddab348cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    im_ratio = cm.shape[1]/cm.shape[0]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=18, pad=12)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=12)\n",
    "    plt.yticks(tick_marks, classes, fontsize=12)\n",
    "\n",
    "    fmt = '.3f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 fontsize = 16, \n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Ground Truth', fontsize=20, labelpad =12)\n",
    "    plt.xlabel('Predicted', fontsize=20, labelpad =12)\n",
    "    plt.xticks(fontsize=16,  rotation=30, ha='right')\n",
    "    plt.yticks(fontsize=16)\n",
    "    cbar = plt.colorbar(orientation=\"vertical\", pad=0.1, ticks=[0, 0.5, 1], fraction=0.045*im_ratio)\n",
    "    cbar.ax.tick_params(labelsize=14)\n",
    "    cbar.ax.set_title('Accuracy',fontsize=16, pad = 12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "## Define function to get the confusion matrix and print out the plot as well\n",
    "def conf_matrix(y_true, y_pred, classes=[\"Laser-off\",'Defect-free','Cracks','Keyhole pores'] ):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # convert to percentage and plot the confusion matrix\n",
    "    cm_pct = cm.astype(float) / cm.sum(axis =1)[:,np.newaxis]\n",
    "    \n",
    "    # classes = le.classes_\n",
    "    print(cm)\n",
    "    plot_confusion_matrix(cm_pct, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e757823-1cb9-4f93-8af3-565ab2d9039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(y_true, y_pred, classes=None, classes_categorical=None, normalize=None, figsize=(10, 10), \n",
    "                          dpi=600, fontsize=10, axis_fontsize=14, tick_size=12):\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize=normalize, labels=classes)\n",
    "    \n",
    "    if normalize == 'true':\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
    "    \n",
    "    cbar = plt.colorbar(cax, ax=ax, shrink=0.65)\n",
    "    \n",
    "    if classes:\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes_categorical, rotation=45, fontsize=tick_size, ha='left')\n",
    "        plt.yticks(tick_marks, classes_categorical, fontsize=tick_size)\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.2f' if normalize else 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=fontsize)\n",
    "    \n",
    "    ax.set_xlabel('Predicted label', fontsize=axis_fontsize)\n",
    "    ax.set_ylabel('True label', fontsize=axis_fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fc3068b-0c5f-48da-a17c-f0098d57d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT_DIR = \"../\"\n",
    "IMAGE_PATH = os.path.join(PROJECT_ROOT_DIR, \"result_images\", 'defect classification', 'class_name_v3', 'ML-baseline', 'audio_visual')\n",
    "model_path = os.path.join(PROJECT_ROOT_DIR, \"trained_models\", 'defect classification', 'class_name_v3', 'ML-baseline', 'audio_visual')\n",
    "os.makedirs(IMAGE_PATH, exist_ok=True)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "Multimodal_dataset_PATH = \"/home/chenlequn/Dataset/LDED_acoustic_visual_monitoring_dataset\"\n",
    "Dataset_path = os.path.join(Multimodal_dataset_PATH, f'25Hz')\n",
    "                            \n",
    "\n",
    "## function for automatically save the diagram/graph into the folder \n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGE_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "plt.rcParams[\"axes.linewidth\"] = 2.50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c67a3c-0c89-4732-bcc9-349f90d2816f",
   "metadata": {},
   "source": [
    "## Import Extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "200a959c-5e04-46a5-9a51-098de5621bd2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample index</th>\n",
       "      <th>Time_Stamps</th>\n",
       "      <th>audio_file_name</th>\n",
       "      <th>image_file_name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class_name_v2</th>\n",
       "      <th>Layer number</th>\n",
       "      <th>Sample number</th>\n",
       "      <th>class_name_v3</th>\n",
       "      <th>rms_energy</th>\n",
       "      <th>...</th>\n",
       "      <th>center_y</th>\n",
       "      <th>contour_area</th>\n",
       "      <th>contour_length</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Vx</th>\n",
       "      <th>Vy</th>\n",
       "      <th>Vz</th>\n",
       "      <th>Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>sample_21_1.wav</td>\n",
       "      <td>sample_21_1.jpg</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>sample_21_2.wav</td>\n",
       "      <td>sample_21_2.jpg</td>\n",
       "      <td>Defect-free</td>\n",
       "      <td>Defect-free</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Defect-free</td>\n",
       "      <td>0.019286</td>\n",
       "      <td>...</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>305442.0</td>\n",
       "      <td>2234.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>sample_21_3.wav</td>\n",
       "      <td>sample_21_3.jpg</td>\n",
       "      <td>Defect-free</td>\n",
       "      <td>Defect-free</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Defect-free</td>\n",
       "      <td>0.019593</td>\n",
       "      <td>...</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>305442.0</td>\n",
       "      <td>2234.000000</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.12</td>\n",
       "      <td>sample_21_4.wav</td>\n",
       "      <td>sample_21_4.jpg</td>\n",
       "      <td>Defect-free</td>\n",
       "      <td>Defect-free</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Defect-free</td>\n",
       "      <td>0.030937</td>\n",
       "      <td>...</td>\n",
       "      <td>230.264496</td>\n",
       "      <td>291865.5</td>\n",
       "      <td>2279.781744</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>2.520</td>\n",
       "      <td>2.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.16</td>\n",
       "      <td>sample_21_5.wav</td>\n",
       "      <td>sample_21_5.jpg</td>\n",
       "      <td>Defect-free</td>\n",
       "      <td>Defect-free</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Defect-free</td>\n",
       "      <td>0.038329</td>\n",
       "      <td>...</td>\n",
       "      <td>229.109962</td>\n",
       "      <td>281970.0</td>\n",
       "      <td>2407.847760</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-1.864</td>\n",
       "      <td>1.662</td>\n",
       "      <td>-2.468</td>\n",
       "      <td>3.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48461</th>\n",
       "      <td>10982</td>\n",
       "      <td>439.24</td>\n",
       "      <td>sample_26_10982.wav</td>\n",
       "      <td>sample_26_10982.jpg</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48462</th>\n",
       "      <td>10983</td>\n",
       "      <td>439.28</td>\n",
       "      <td>sample_26_10983.wav</td>\n",
       "      <td>sample_26_10983.jpg</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>0.008347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48463</th>\n",
       "      <td>10984</td>\n",
       "      <td>439.32</td>\n",
       "      <td>sample_26_10984.wav</td>\n",
       "      <td>sample_26_10984.jpg</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48464</th>\n",
       "      <td>10985</td>\n",
       "      <td>439.36</td>\n",
       "      <td>sample_26_10985.wav</td>\n",
       "      <td>sample_26_10985.jpg</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48465</th>\n",
       "      <td>10986</td>\n",
       "      <td>439.40</td>\n",
       "      <td>sample_26_10986.wav</td>\n",
       "      <td>sample_26_10986.jpg</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>Laser-off</td>\n",
       "      <td>0.013110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36557 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample index  Time_Stamps      audio_file_name      image_file_name  \\\n",
       "0                 1         0.00      sample_21_1.wav      sample_21_1.jpg   \n",
       "1                 2         0.04      sample_21_2.wav      sample_21_2.jpg   \n",
       "2                 3         0.08      sample_21_3.wav      sample_21_3.jpg   \n",
       "3                 4         0.12      sample_21_4.wav      sample_21_4.jpg   \n",
       "4                 5         0.16      sample_21_5.wav      sample_21_5.jpg   \n",
       "...             ...          ...                  ...                  ...   \n",
       "48461         10982       439.24  sample_26_10982.wav  sample_26_10982.jpg   \n",
       "48462         10983       439.28  sample_26_10983.wav  sample_26_10983.jpg   \n",
       "48463         10984       439.32  sample_26_10984.wav  sample_26_10984.jpg   \n",
       "48464         10985       439.36  sample_26_10985.wav  sample_26_10985.jpg   \n",
       "48465         10986       439.40  sample_26_10986.wav  sample_26_10986.jpg   \n",
       "\n",
       "        class_name class_name_v2  Layer number  Sample number class_name_v3  \\\n",
       "0        Laser-off     Laser-off           1.0             21     Laser-off   \n",
       "1      Defect-free   Defect-free           1.0             21   Defect-free   \n",
       "2      Defect-free   Defect-free           1.0             21   Defect-free   \n",
       "3      Defect-free   Defect-free           1.0             21   Defect-free   \n",
       "4      Defect-free   Defect-free           1.0             21   Defect-free   \n",
       "...            ...           ...           ...            ...           ...   \n",
       "48461    Laser-off     Laser-off           NaN             26     Laser-off   \n",
       "48462    Laser-off     Laser-off           NaN             26     Laser-off   \n",
       "48463    Laser-off     Laser-off           NaN             26     Laser-off   \n",
       "48464    Laser-off     Laser-off           NaN             26     Laser-off   \n",
       "48465    Laser-off     Laser-off           NaN             26     Laser-off   \n",
       "\n",
       "       rms_energy  ...    center_y  contour_area  contour_length      X  \\\n",
       "0        0.009018  ...    0.000000           0.0        0.000000  0.000   \n",
       "1        0.019286  ...  239.000000      305442.0     2234.000000  0.000   \n",
       "2        0.019593  ...  239.000000      305442.0     2234.000000 -0.010   \n",
       "3        0.030937  ...  230.264496      291865.5     2279.781744 -0.007   \n",
       "4        0.038329  ...  229.109962      281970.0     2407.847760 -0.111   \n",
       "...           ...  ...         ...           ...             ...    ...   \n",
       "48461    0.011000  ...    0.000000           0.0        0.000000  0.000   \n",
       "48462    0.008347  ...    0.000000           0.0        0.000000  0.000   \n",
       "48463    0.011081  ...    0.000000           0.0        0.000000  0.000   \n",
       "48464    0.011044  ...    0.000000           0.0        0.000000  0.000   \n",
       "48465    0.013110  ...    0.000000           0.0        0.000000  0.000   \n",
       "\n",
       "           Y      Z     Vx     Vy     Vz  Speed  \n",
       "0      0.000  0.000  0.000 -0.000  0.000  0.000  \n",
       "1     -0.000  0.001 -0.074 -0.074  0.000  0.105  \n",
       "2      0.015 -0.007 -0.051  0.026 -0.051  0.077  \n",
       "3      0.016  0.010  0.173 -0.222  2.520  2.536  \n",
       "4      0.123 -0.057 -1.864  1.662 -2.468  3.511  \n",
       "...      ...    ...    ...    ...    ...    ...  \n",
       "48461  0.000  0.000 -0.076  0.025  0.000  0.080  \n",
       "48462  0.000  0.000 -0.076  0.025  0.000  0.080  \n",
       "48463  0.000  0.000 -0.076  0.025  0.000  0.080  \n",
       "48464  0.000  0.000 -0.076  0.025  0.000  0.080  \n",
       "48465  0.000  0.000 -0.076  0.025  0.000  0.080  \n",
       "\n",
       "[36557 rows x 135 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data back from the HDF5 file into a new DataFrame\n",
    "df_multimodal = pd.read_hdf(os.path.join(Dataset_path, 'spatiotemporal_fused_multimodal.h5'), key='df')\n",
    "df_multimodal = df_multimodal.dropna(subset=['class_name_v3'])\n",
    "df_multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d93e876-fbba-4c62-849d-d8e701f36c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Laser-off', 'Defect-free', 'Laser defocus', 'Keyhole pores']\n",
       "Categories (4, object): ['Defect-free', 'Keyhole pores', 'Laser defocus', 'Laser-off']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_multimodal['class_name_v3'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825b9c5c-6cb9-4d83-9054-94db84ddc7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sample index', 'Time_Stamps', 'audio_file_name', 'image_file_name',\n",
      "       'class_name', 'class_name_v2', 'Layer number', 'Sample number',\n",
      "       'class_name_v3', 'rms_energy',\n",
      "       ...\n",
      "       'center_y', 'contour_area', 'contour_length', 'X', 'Y', 'Z', 'Vx', 'Vy',\n",
      "       'Vz', 'Speed'],\n",
      "      dtype='object', length=135)\n"
     ]
    }
   ],
   "source": [
    "print (df_multimodal.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f68658-2764-4a2a-a404-d98a3004d18d",
   "metadata": {},
   "source": [
    "## Constructing labels and input features for training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c943ef84-45b5-4a3c-909f-fda0fb71615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label = df_multimodal['class_name'].to_list()\n",
    "y = df_multimodal['class_name_v3'].to_list()\n",
    "\n",
    "# Drop non-feature columns and store the result in a variable\n",
    "# Drop non-feature columns\n",
    "non_feature_columns = ['sample index', 'Time_Stamps', 'audio_file_name', 'image_file_name',\n",
    "                       'class_name', 'class_name_v2', 'class_name_v3', 'Layer number', 'Sample number', 'X', 'Y', 'Z', 'Vx', 'Vy', 'Vz', 'Speed']\n",
    "\n",
    "    \n",
    "X_all = df_multimodal.drop(columns=non_feature_columns).to_numpy()\n",
    "\n",
    "redundant_audio_features = ['dynamic_complexity','loudness']\n",
    "\n",
    "\n",
    "X_audio = df_multimodal[['rms_energy', 'amplitude_envelope_mean',\n",
    "                           'amplitude_envelope_std', 'zero_crossing_rate', 'dynamic_complexity',\n",
    "                           'loudness', 'loudness_vickers', 'spectral_centroid_mean',\n",
    "                           'spectral_centroid_std', 'spectral_complexity_mean',\n",
    "                           'spectral_complexity_std', 'spectral_contrast_0_mean',\n",
    "                           'spectral_contrast_0_std', 'spectral_contrast_1_mean',\n",
    "                           'spectral_contrast_1_std', 'spectral_contrast_2_mean',\n",
    "                           'spectral_contrast_2_std', 'spectral_contrast_3_mean',\n",
    "                           'spectral_contrast_3_std', 'spectral_contrast_4_mean',\n",
    "                           'spectral_contrast_4_std', 'spectral_contrast_5_mean',\n",
    "                           'spectral_contrast_5_std', 'spectral_valley_0_mean',\n",
    "                           'spectral_valley_0_std', 'spectral_valley_1_mean',\n",
    "                           'spectral_valley_1_std', 'spectral_valley_2_mean',\n",
    "                           'spectral_valley_2_std', 'spectral_valley_3_mean',\n",
    "                           'spectral_valley_3_std', 'spectral_valley_4_mean',\n",
    "                           'spectral_valley_4_std', 'spectral_valley_5_mean',\n",
    "                           'spectral_valley_5_std', 'spectral_decrease_mean',\n",
    "                           'spectral_decrease_std', 'spectral_energy_mean', 'spectral_energy_std',\n",
    "                           'spectral_energy_band_ratio_mean', 'spectral_energy_band_ratio_std',\n",
    "                           'spectral_flatness_mean', 'spectral_flatness_std', 'spectral_flux_mean',\n",
    "                           'spectral_flux_std', 'spectral_rolloff_mean', 'spectral_rolloff_std',\n",
    "                           'spectral_strong_peak_mean', 'spectral_strong_peak_std',\n",
    "                           'spectral_variance_mean', 'spectral_variance_std',\n",
    "                           'spectral_skewness_mean', 'spectral_skewness_std',\n",
    "                           'spectral_kurtosis_mean', 'spectral_kurtosis_std',\n",
    "                           'spectral_crest_factor_mean', 'spectral_crest_factor_std',\n",
    "                           'mfcc_0_mean', 'mfcc_0_std', 'mfcc_1_mean', 'mfcc_1_std', 'mfcc_2_mean',\n",
    "                           'mfcc_2_std', 'mfcc_3_mean', 'mfcc_3_std', 'mfcc_4_mean', 'mfcc_4_std',\n",
    "                           'mfcc_5_mean', 'mfcc_5_std', 'mfcc_6_mean', 'mfcc_6_std', 'mfcc_7_mean',\n",
    "                           'mfcc_7_std', 'mfcc_8_mean', 'mfcc_8_std', 'mfcc_9_mean', 'mfcc_9_std',\n",
    "                           'mfcc_10_mean', 'mfcc_10_std', 'mfcc_11_mean', 'mfcc_11_std',\n",
    "                           'mfcc_12_mean', 'mfcc_12_std']].drop(columns=redundant_audio_features).to_numpy()\n",
    "                     \n",
    "\n",
    "X_vision = df_multimodal[['max_contour_area', 'rectangle_angle',\n",
    "                          'rectangle_width', 'rectangle_height', 'ellipse_angle', 'ellipse_width',\n",
    "                          'ellipse_height', 'max_hull', 'm00', 'm10', 'm01', 'm20', 'm11', 'm02',\n",
    "                          'm30', 'm21', 'm12', 'm03', 'mu20', 'mu11', 'mu02', 'mu30', 'mu21',\n",
    "                          'mu12', 'mu03', 'nu20', 'nu11', 'nu02', 'nu30', 'nu21', 'nu12', 'nu03',\n",
    "                          'center_x', 'center_y', 'contour_area', 'contour_length']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c4d11-b280-4d95-8795-26373cd4b903",
   "metadata": {},
   "source": [
    "# ML Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b3cfc83-04ec-4c7b-85fd-f1b774e7749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accuracy_mean_list = []\n",
    "all_accuracy_std_list = []\n",
    "vision_accuracy_mean_list = []\n",
    "vision_accuracy_std_list = []\n",
    "acoustic_accuracy_mean_list = []\n",
    "acoustic_accuracy_std_list = []\n",
    "\n",
    "all_auc_mean = []\n",
    "all_auc_std = []\n",
    "vision_auc_mean = []\n",
    "vision_auc_std = []\n",
    "acoustic_auc_mean = []\n",
    "acoustic_auc_std = []\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5695df7-7f49-4eb0-89d1-40720aa45016",
   "metadata": {},
   "source": [
    "### Train val test split\n",
    "- Train 80%, Val 10%, Test 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "044c9309-5bca-410e-98f5-826c152c2b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29245, 3656, 3656)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = np.array(y)\n",
    "\n",
    "# First split: Separate out the training set (80% of original)\n",
    "train_indices, temp_indices = train_test_split(\n",
    "    np.arange(len(df_multimodal)), test_size=0.2, random_state=0, stratify=y_array)\n",
    "\n",
    "# Second split: Separate out the validation and test sets (each will be 10% of original)\n",
    "val_indices, test_indices = train_test_split(\n",
    "    temp_indices, test_size=0.5, random_state=0, stratify=y_array[temp_indices])\n",
    "\n",
    "# Check the shape of the indices for train, val, and test splits\n",
    "len(train_indices), len(val_indices), len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e93491a7-ca0a-474c-8285-e5a4561fceed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'split_indices.pkl'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_indices = {\n",
    "    'train_indices': train_indices,\n",
    "    'val_indices': val_indices,\n",
    "    'test_indices': test_indices\n",
    "}\n",
    "\n",
    "split_indices_path = 'split_indices.pkl'\n",
    "\n",
    "with open(split_indices_path, 'wb') as f:\n",
    "    pickle.dump(split_indices, f)\n",
    "\n",
    "split_indices_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91cf4221-252f-42e6-8225-4a5fdba2705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_indices' (ndarray)\n",
      "Stored 'val_indices' (ndarray)\n",
      "Stored 'test_indices' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store train_indices\n",
    "%store val_indices\n",
    "%store test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37c8bb90-4067-4a05-89b0-4d9a9b1a89fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, val, and test datasets for traditional ML models\n",
    "X_all_train = X_all[train_indices, :]\n",
    "Y_train = np.array(y)[train_indices]\n",
    "X_all_val = X_all[val_indices, :]\n",
    "Y_val = np.array(y)[val_indices]\n",
    "X_all_test = X_all[test_indices, :]\n",
    "Y_test = np.array(y)[test_indices]\n",
    "\n",
    "# For single modality datasets (audio and vision)\n",
    "X_audio_train = X_audio[train_indices, :]\n",
    "X_audio_val = X_audio[val_indices, :]\n",
    "X_audio_test = X_audio[test_indices, :]\n",
    "\n",
    "X_vision_train = X_vision[train_indices, :]\n",
    "X_vision_val = X_vision[val_indices, :]\n",
    "X_vision_test = X_vision[test_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "237fc080-c94c-4365-a4d6-49beaf39131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "Y_train_encoded = le.transform(Y_train)\n",
    "Y_val_encoded = le.transform(Y_val)\n",
    "Y_test_encoded = le.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a3c0481-49c9-4d59-88ed-48f97fd8ce61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 29245\n",
      "Validation set size: 7238\n",
      "Testing set size: 74\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set size: {len(Y_train)}\")\n",
    "print(f\"Validation set size: {len(Y_val)}\")\n",
    "print(f\"Testing set size: {len(Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48c85ab4-7c33-45dd-8269-e2ae146756d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Defect-free', 'Keyhole pores', 'Laser defocus', 'Laser-off'],\n",
       "      dtype='<U13')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6643b85-fe03-4a13-ab2e-d52d4e2ae2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 3, ..., 2, 1, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b15c7-f985-44e9-acde-192fdcd30377",
   "metadata": {},
   "source": [
    "### Compute class weight\n",
    "\n",
    "This is for treating the imbalanced class, which is calculating the class weight and use it for weighting the loss function (during training only).\n",
    "\n",
    "`'balanced'` => n_samples / (n_classes * np.bincount(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7376148-eea2-4441-993a-e287123c2123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class weights: [1.20231048 1.83101678 1.47226138 0.51469553]\n",
      "class weights encoded: [1.20231048 1.83101678 1.47226138 0.51469553]\n",
      "class        : ['Defect-free', 'Keyhole pores', 'Laser defocus', 'Laser-off']\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes = np.unique(Y_train),\n",
    "                                                 y = Y_train)\n",
    "\n",
    "class_weights_encoded = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes = np.unique(Y_train_encoded),\n",
    "                                                 y = Y_train_encoded)\n",
    "\n",
    "\n",
    "class_names = (le.classes_).tolist()\n",
    "print(f\"class weights: {class_weights}\")\n",
    "print(f\"class weights encoded: {class_weights_encoded}\")\n",
    "print(f\"class        : {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "645de9f1-b276-4ce0-a1c1-5bdbc9140c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class weights: [1.20231048 1.83101678 1.47226138 0.51469553]\n",
      "class        : ['Defect-free' 'Keyhole pores' 'Laser defocus' 'Laser-off']\n"
     ]
    }
   ],
   "source": [
    "print(f\"class weights: {class_weights}\")\n",
    "print(f\"class        : {np.unique(le.inverse_transform(Y_train_encoded))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1f8b9d-473c-4557-bd94-c198fec4fc06",
   "metadata": {},
   "source": [
    "### Data standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce13e0ff-424b-4c6d-98c3-4c0f82f444b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For \"all\" modality\n",
    "scaler_all = preprocessing.StandardScaler()\n",
    "X_all_train_transformed = scaler_all.fit_transform(X_all_train)\n",
    "X_all_val_transformed = scaler_all.transform(X_all_val)\n",
    "X_all_test_transformed = scaler_all.transform(X_all_test)\n",
    "\n",
    "# For \"audio\" modality\n",
    "scaler_audio = preprocessing.StandardScaler()\n",
    "X_audio_train_transformed = scaler_audio.fit_transform(X_audio_train)\n",
    "X_audio_val_transformed = scaler_audio.transform(X_audio_val)\n",
    "X_audio_test_transformed = scaler_audio.transform(X_audio_test)\n",
    "\n",
    "# For \"vision\" modality\n",
    "scaler_vision = preprocessing.StandardScaler()\n",
    "X_vision_train_transformed = scaler_vision.fit_transform(X_vision_train)\n",
    "X_vision_val_transformed = scaler_vision.transform(X_vision_val)\n",
    "X_vision_test_transformed = scaler_vision.transform(X_vision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d83ac853-3f6f-460d-91f2-fccbcc6257b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.81480926,  1.42071936,  0.69850722, ...,  0.40508304,\n",
       "         0.12286475,  0.63778654],\n",
       "       [-0.96847554, -1.03018035, -0.83527196, ..., -0.94187531,\n",
       "        -0.60054493, -0.89814704],\n",
       "       [-1.11846186, -1.04617461, -0.9335314 , ..., -0.94187531,\n",
       "        -0.60054493, -0.89814704],\n",
       "       ...,\n",
       "       [ 0.2167297 ,  0.05974038,  0.41845307, ...,  0.5200759 ,\n",
       "        -0.19916313,  0.20267869],\n",
       "       [ 2.65677087,  2.85071455,  1.72459179, ...,  0.46016599,\n",
       "        -0.10573942,  0.31938169],\n",
       "       [ 0.21043028,  0.15595506,  0.32574587, ...,  0.39384568,\n",
       "        -0.10392147,  0.2957848 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d357b37c-73d4-4eb0-af91-f20007caa522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the scaler objects\n",
    "with open('StandardScaler_all.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_all, file)\n",
    "\n",
    "with open('StandardScaler_audio.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_audio, file)\n",
    "    \n",
    "with open('StandardScaler_vision.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_vision, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd036153-41cd-43b0-8b39-f4d3ce34d4ed",
   "metadata": {},
   "source": [
    "## ML training, with hyperparameter optimization, cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f32e6-bc83-4979-816f-fdb320de9e1a",
   "metadata": {},
   "source": [
    "Predicts the melt pool temperature based on features of the other sensing models, iterating over the algorithms:\n",
    "\n",
    "- K nearest neighbor classification: 'KNN'\n",
    "\n",
    "- Decision Tree classification: 'DT'\n",
    "\n",
    "- Adaptive Boosting classification: 'AdaBoost'\n",
    "\n",
    "- Random Forests classification 'RF'\n",
    "  \n",
    "- Gaussian Process classification 'GPR'\n",
    "  \n",
    "- Support Vector classification 'SVR'\n",
    "  \n",
    "- Gradient Boosting classification 'GB'\n",
    "  \n",
    "- Nerual Network classification 'NN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f199d9eb-71f8-4c25-9551-c6707d8639de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight_computed = {\n",
    "#     class_names[0]: class_weights_all[0], \n",
    "#     class_names[1]: class_weights_all[1], \n",
    "#     class_names[2]: class_weights_all[2], \n",
    "#     class_names[3]: class_weights_all[3],\n",
    "# }\n",
    "# print (class_weight_computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60b44e9f-31d5-49c3-b415-1748b192359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.2023104752507812, 1: 1.8310167793638867, 2: 1.4722613773660893, 3: 0.5146955297430482}\n"
     ]
    }
   ],
   "source": [
    "class_weight_computed = {\n",
    "    0: class_weights[0], \n",
    "    1: class_weights[1], \n",
    "    2: class_weights[2], \n",
    "    3: class_weights[3],\n",
    "}\n",
    "print (class_weight_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6882cb1-cb18-4926-a80d-2011f447ed2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step1: Hyperparameter tuning: RandomizedSearchCV\n",
    "\n",
    "- Considering the feature space and the data volume, RandomizedSearchCV is much more faster to do.\n",
    "- Get a initial result for hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fe7bc0c-5db6-4efa-a36f-c65c547e8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform\n",
    "import numpy as np\n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "# -------------------------1 For KNN:-----------------------\n",
    "knn_distributions = {\n",
    "    'n_neighbors': sp_randint(1, 50),\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "knn_search = RandomizedSearchCV(neighbors.KNeighborsClassifier(), knn_distributions, n_iter=n_iter_search, \n",
    "                                scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42)\n",
    "\n",
    "# ------------------2 For Decision Trees:-----------------------\n",
    "dt_distributions = {\n",
    "    'min_samples_split': sp_randint(2, 20),\n",
    "    'min_samples_leaf': sp_randint(1, 20),\n",
    "    'max_depth': sp_randint(1, 50),\n",
    "    'ccp_alpha': uniform(0.0, 0.05)\n",
    "}\n",
    "dt_search = RandomizedSearchCV(tree.DecisionTreeClassifier(class_weight=class_weight_computed), dt_distributions,\n",
    "                               n_iter=n_iter_search, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42)\n",
    "\n",
    "# ------------- 3 for Logistic Regression:----------\n",
    "lr_distributions = {\n",
    "    'solver': ['lbfgs', 'sag'],\n",
    "    'penalty': ['l2'],\n",
    "    'C': uniform(0.01, 10),\n",
    "    'max_iter': sp_randint(1000, 10000)\n",
    "}\n",
    "lr_search = RandomizedSearchCV(LogisticRegression(class_weight=class_weight_computed), lr_distributions,\n",
    "                               n_iter=n_iter_search, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42)\n",
    "\n",
    "\n",
    "# ---------------4 For Random Forest:-------------------\n",
    "rf_distributions = {\n",
    "    'n_estimators': sp_randint(1, 500),\n",
    "    'min_samples_split': sp_randint(2, 20),\n",
    "    'min_samples_leaf': sp_randint(1, 20),\n",
    "    'max_depth': sp_randint(1, 100),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "rf_search = RandomizedSearchCV(RandomForestClassifier(class_weight=class_weight_computed), rf_distributions,\n",
    "                               n_iter=n_iter_search, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42)\n",
    "\n",
    "\n",
    "# ------------- 5 for BalancedRandomForestClassifier -----\n",
    "brf_distributions = {\n",
    "    'n_estimators': sp_randint(1, 500),\n",
    "    'min_samples_split': sp_randint(2, 20),\n",
    "    'min_samples_leaf': sp_randint(1, 20),\n",
    "    'max_depth': sp_randint(1, 50),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "brf_search = RandomizedSearchCV(BalancedRandomForestClassifier(), brf_distributions, \n",
    "                                n_iter=n_iter_search, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42)\n",
    "\n",
    "\n",
    "# ------------- 6 for RUSBoostClassifier---------------\n",
    "rusboost_distributions = {\n",
    "    'n_estimators': sp_randint(1, 500),\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.5, 1.0]\n",
    "}\n",
    "rusboost_search = RandomizedSearchCV(RUSBoostClassifier(), rusboost_distributions,\n",
    "                                     n_iter=n_iter_search, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42)\n",
    "\n",
    "\n",
    "# ------------------7 For AdaBoost:----------------------\n",
    "ada_distributions = {\n",
    "    'n_estimators': sp_randint(1, 500),\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "    'learning_rate': uniform(0.5, 1.5)\n",
    "}\n",
    "ada_search = RandomizedSearchCV(AdaBoostClassifier(), ada_distributions, n_iter=n_iter_search,\n",
    "                                scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42)\n",
    "\n",
    "\n",
    "# # ------------8 For Gaussian Process:------------\n",
    "# gp_distributions = {\n",
    "#     'kernel': [1.0 * RBF(1.0)]\n",
    "# }\n",
    "# gp_search = RandomizedSearchCV(GaussianProcessClassifier(), gp_distributions, n_iter=n_iter_search,\n",
    "#                                scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42)\n",
    "\n",
    "\n",
    "# ------------ 9 For Neural Network:-----------\n",
    "nn_distributions = {\n",
    "    'hidden_layer_sizes': [(sp_randint(16, 256).rvs(), sp_randint(16, 256).rvs(), sp_randint(16, 256).rvs()) for _ in range(10)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': uniform(0.001, 0.1),\n",
    "    'learning_rate': ['adaptive'],\n",
    "    'max_iter': sp_randint(1000, 20000),\n",
    "    'early_stopping': [True],\n",
    "    'validation_fraction': [0.1]\n",
    "}\n",
    "nn_search = RandomizedSearchCV(MLPClassifier(), nn_distributions, n_iter=n_iter_search, \n",
    "                               scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42)\n",
    "\n",
    "\n",
    "## ------------ 10 For Xboost:-----------\n",
    "xgb_distributions = {\n",
    "    'n_estimators': sp_randint(50, 500),\n",
    "    'learning_rate': uniform(0.01, 0.5),\n",
    "    'subsample': uniform(0.5, 0.5),\n",
    "    'max_depth': list(range(1, 50)),\n",
    "    'colsample_bytree': uniform(0.5, 0.5),\n",
    "    'min_child_weight': list(range(1, 20)),\n",
    "    'gamma': uniform(0, 2)\n",
    "}\n",
    "xgb_search = RandomizedSearchCV(xgb.XGBClassifier(objective='multi:softmax'), xgb_distributions, \n",
    "                                n_iter=n_iter_search, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# ------------ 11 for LightGBM -----------\n",
    "lgb_distributions = {\n",
    "    'n_estimators': sp_randint(50, 500),\n",
    "    'learning_rate': uniform(0.01, 0.5),\n",
    "    'subsample': uniform(0.5, 0.5),\n",
    "    'num_leaves': sp_randint(20, 150),\n",
    "    'max_depth': sp_randint(1, 50),\n",
    "    'colsample_bytree': uniform(0.5, 0.5),\n",
    "    'min_child_weight': sp_randint(1, 20),\n",
    "    'reg_alpha': uniform(0, 2),\n",
    "    'reg_lambda': uniform(0, 2),\n",
    "}\n",
    "\n",
    "lgb_search = RandomizedSearchCV(lgb.LGBMClassifier(objective='multiclass', metric='multi_logloss'), \n",
    "                                lgb_distributions, n_iter=n_iter_search, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42)\n",
    "\n",
    "\n",
    "# ----------------12 For Support Vector Machine:-----------------\n",
    "svm_distributions = {\n",
    "    'C': uniform(0.1, 1000),\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': sp_randint(1, 10),\n",
    "    'gamma': uniform(1e-4, 1e-1)\n",
    "}\n",
    "svm_search = RandomizedSearchCV(SVC(class_weight=class_weight_computed), svm_distributions, \n",
    "                                n_iter=n_iter_search, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42)\n",
    "\n",
    "\n",
    "# ---------  13 For GradientBoostingClassifier:---------------------\n",
    "gboost_distributions = {\n",
    "    'n_estimators': sp_randint(1, 500),\n",
    "    'learning_rate': uniform(0.01, 0.5),\n",
    "    'subsample': uniform(0.5, 0.5),\n",
    "    'max_depth': sp_randint(1, 50),\n",
    "    'min_samples_split': sp_randint(2, 20),\n",
    "    'min_samples_leaf': sp_randint(1, 20),\n",
    "    'n_iter_no_change': [10],\n",
    "    'tol': [1e-4]\n",
    "}\n",
    "gboost_search = RandomizedSearchCV(GradientBoostingClassifier(), gboost_distributions, \n",
    "                                   n_iter=n_iter_search, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ad3e7bf-19b4-4253-9ce1-ce0c35c17ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14622.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_all_train_transformed)*0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a28323c-f7d2-443c-819c-aabf51c4afc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### RandomizedSearchCV Initialization & Model Fitting (ALL features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b12efb22-ce3f-4b90-aa20-99377e93df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a subset of your data for faster training\n",
    "n_samples = 14600 # 50% of the total data\n",
    "X_subset, y_subset = resample(X_all_train_transformed, Y_train_encoded, n_samples=n_samples, random_state=42)\n",
    "\n",
    "# Sample a subset of your data for faster training\n",
    "n_samples = 3000  # 10% of the total data\n",
    "X_sample, y_sample = resample(X_all_train_transformed, Y_train_encoded, n_samples=n_samples, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec6dc3-eee3-4821-b3d2-b4721933f945",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/chenlequn/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "\n",
    "# 1. KNN\n",
    "knn_search.fit(X_subset, y_subset)\n",
    "\n",
    "# 2. Decision Tree\n",
    "dt_search.fit(X_subset, y_subset)\n",
    "\n",
    "# 3. Logistic Regression:\n",
    "lr_search.fit(X_subset, y_subset)\n",
    "\n",
    "# 4. Random Forest\n",
    "rf_search.fit(X_subset, y_subset)\n",
    "\n",
    "# 5. Balanced Forest\n",
    "brf_search.fit(X_subset, y_subset)\n",
    "\n",
    "# 6. RUSBoost\n",
    "rusboost_search.fit(X_subset, y_subset)\n",
    "\n",
    "# 7. AdaBoost \n",
    "ada_search.fit(X_subset, y_subset)\n",
    "\n",
    "# 8. Gaussian Process \n",
    "gp_search.fit(X_sample, y_sample)\n",
    "\n",
    "# 9. Neural Network:\n",
    "nn_search.fit(X_subset, y_subset)\n",
    "\n",
    "# 10. XGBoost:\n",
    "xgb_search.fit(X_sample, y_sample)\n",
    "\n",
    "# 11. LightGBM\n",
    "lgb_search.fit(X_sample, y_sample)\n",
    "\n",
    "# 12. SVM:\n",
    "svm_search.fit(X_subset, y_subset)\n",
    "\n",
    "# 13. GradientBoostingClassifier\n",
    "gboost_search.fit(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62abfe4-b260-483c-affb-f739ce63536b",
   "metadata": {},
   "source": [
    "### Best hyperparameters of each models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54f469-ac7b-47ca-afbb-d35859cbb767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "print(\"Best parameters for KNN: \", knn_search.best_params_)\n",
    "print(\"Best cross-validation score for KNN: {:.2f}\\n\".format(knn_search.best_score_))\n",
    "\n",
    "# 2\n",
    "print(\"Best parameters for DT: \", dt_search.best_params_)\n",
    "print(\"Best cross-validation score for DT: {:.2f}\\n\".format(dt_search.best_score_))\n",
    "\n",
    "# 3\n",
    "print(\"Best parameters for LR: \", lr_search.best_params_)\n",
    "print(\"Best cross-validation score for LR: {:.2f}\\n\".format(lr_search.best_score_))\n",
    "\n",
    "# 4\n",
    "print(\"Best parameters for RF: \", rf_search.best_params_)\n",
    "print(\"Best cross-validation score for RF: {:.2f}\\n\".format(rf_search.best_score_))\n",
    "\n",
    "# 5\n",
    "print(\"Best parameters for BalancedRandomForestClassifier: \", brf_search.best_params_)\n",
    "print(\"Best cross-validation score for BalancedRandomForestClassifier: {:.2f}\\n\".format(brf_search.best_score_))\n",
    "\n",
    "# 6\n",
    "print(\"Best parameters for RUSBoostClassifier: \", rusboost_search.best_params_)\n",
    "print(\"Best cross-validation score for RUSBoostClassifier: {:.2f}\\n\".format(rusboost_search.best_score_))\n",
    "\n",
    "# 7 \n",
    "print(\"Best parameters for Ada: \", ada_search.best_params_)\n",
    "print(\"Best cross-validation score for Ada: {:.2f}\\n\".format(ada_search.best_score_))\n",
    "\n",
    "# 8\n",
    "print(\"Best parameters for GP: \", gp_search.best_params_)\n",
    "print(\"Best cross-validation score for GP: {:.2f}\\n\".format(gp_search.best_score_))\n",
    "\n",
    "# 9\n",
    "print(\"Best parameters for NN: \", nn_search.best_params_)\n",
    "print(\"Best cross-validation score for NN: {:.2f}\\n\".format(nn_search.best_score_))\n",
    "\n",
    "# 10\n",
    "print(\"Best parameters for XGBoost: \", xgb_search.best_params_)\n",
    "print(\"Best cross-validation score for XGBoost: {:.2f}\\n\".format(xgb_search.best_score_))\n",
    "\n",
    "# 11\n",
    "print(\"Best parameters for LightGBM: \", lgb_search.best_params_)\n",
    "print(\"Best cross-validation score for LightGBM: {:.2f}\\n\".format(lgb_search.best_score_))\n",
    "\n",
    "# 12\n",
    "print(\"Best parameters for SVM: \", svm_search.best_params_)\n",
    "print(\"Best cross-validation score for SVM: {:.2f}\\n\".format(svm_search.best_score_))\n",
    "\n",
    "# 13. GradientBoostingClassifier\n",
    "print(\"Best parameters for GB: \", gboost_search.best_params_)\n",
    "print(\"Best cross-validation score for GB: {:.2f}\\n\".format(gboost_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3acc96-fcd0-4224-9c74-e9b9c459f645",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2: Train the model using the best hyperparameter on the trianing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727051d5-47e0-49ac-812a-f2a12cea4659",
   "metadata": {},
   "source": [
    "### Best Hyperparameters (for class_v2, three categories)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e30d7d52-d06c-4684-bccc-8122890958ca",
   "metadata": {},
   "source": [
    "Best parameters for KNN:  {'n_neighbors': 12, 'weights': 'distance'}\n",
    "Best cross-validation score for KNN: 0.93\n",
    "\n",
    "Best parameters for DT:  {'ccp_alpha': 3.893829205071642e-05, 'max_depth': 21, 'min_samples_leaf': 1, 'min_samples_split': 13}\n",
    "Best cross-validation score for DT: 0.92\n",
    "\n",
    "Best parameters for LR:  {'C': 5.152344384136116, 'max_iter': 2528, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "Best cross-validation score for LR: 0.94\n",
    "\n",
    "Best parameters for RF:  {'bootstrap': False, 'max_depth': 64, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 307}\n",
    "Best cross-validation score for RF: 0.96\n",
    "\n",
    "Best parameters for BalancedRandomForestClassifier:  {'bootstrap': False, 'max_depth': 23, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 17, 'n_estimators': 237}\n",
    "Best cross-validation score for BalancedRandomForestClassifier: 0.95\n",
    "\n",
    "Best parameters for RUSBoostClassifier:  {'learning_rate': 0.1, 'n_estimators': 150}\n",
    "Best cross-validation score for RUSBoostClassifier: 0.89\n",
    "\n",
    "Best parameters for Ada:  {'algorithm': 'SAMME', 'learning_rate': 0.5696756190799965, 'n_estimators': 307}\n",
    "Best cross-validation score for Ada: 0.90\n",
    "\n",
    "Best parameters for GP:  {'kernel': 1**2 * RBF(length_scale=1)}\n",
    "Best cross-validation score for GP: 0.89\n",
    "\n",
    "Best parameters for NN:  {'activation': 'relu', 'alpha': 0.07653614103176526, 'early_stopping': True, 'hidden_layer_sizes': (229, 255, 168), 'learning_rate': 'adaptive', 'max_iter': 11805, 'solver': 'adam', 'validation_fraction': 0.1}\n",
    "Best cross-validation score for NN: 0.96\n",
    "\n",
    "Best parameters for XGBoost:  {'colsample_bytree': 0.6154469128110744, 'gamma': 0.48205093205202343, 'learning_rate': 0.3516317594127291, 'max_depth': 44, 'min_child_weight': 8, 'n_estimators': 480, 'subsample': 0.5866823267538861}\n",
    "Best cross-validation score for XGBoost: 0.94\n",
    "\n",
    "Best parameters for LightGBM:  {'colsample_bytree': 0.7956488938538635, 'learning_rate': 0.1473608964950321, 'max_depth': 35, 'min_child_weight': 1, 'n_estimators': 276, 'num_leaves': 120, 'reg_alpha': 1.9434241907782075, 'reg_lambda': 1.6978276485321677, 'subsample': 0.8608647605824367}\n",
    "Best cross-validation score for LightGBM: 0.94\n",
    "\n",
    "Best parameters for SVM:  {'C': 524.8564316322379, 'degree': 9, 'gamma': 0.029222914019804192, 'kernel': 'rbf'}\n",
    "Best cross-validation score for SVM: 0.96\n",
    "\n",
    "Best parameters for GB:  {'learning_rate': 0.2259725093210579, 'max_depth': 49, 'min_samples_leaf': 10, 'min_samples_split': 17, 'n_estimators': 271, 'n_iter_no_change': 10, 'subsample': 0.728034992108518, 'tol': 0.0001}\n",
    "Best cross-validation score for GB: 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa35862-6d71-40de-9950-838997353379",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_all_train_transformed)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dce8f5-c133-43e3-aac8-7c486c5b1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 29245 # 100% of the total data\n",
    "X_subset, y_subset = resample(X_all_train_transformed, Y_train_encoded, n_samples=n_samples, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9fd0f8-23b8-4a57-8dfb-0f9e90bcf049",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. AdaBoost\n",
    "ada_model = AdaBoostClassifier(algorithm='SAMME', learning_rate=0.5696756190799965, n_estimators=307)\n",
    "ada_model.fit(X_subset, y_subset)\n",
    "ada_val_score = ada_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "print(f\"Validation score for AdaBoost: {ada_val_score:.2f}\")\n",
    "\n",
    "\n",
    "# 2. Decision Tree\n",
    "dt_model = tree.DecisionTreeClassifier(ccp_alpha=3.893829205071642e-05, max_depth=21,\n",
    "                                       min_samples_leaf=1, min_samples_split=13)\n",
    "dt_model.fit(X_subset, y_subset)\n",
    "dt_val_score = dt_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "print(f\"Validation score for DT: {dt_val_score:.2f}\")\n",
    "\n",
    "# 3. Logistic Regression\n",
    "lr_model = LogisticRegression(C=5.152344384136116, max_iter=2528, penalty='l2', solver='lbfgs')\n",
    "lr_model.fit(X_subset, y_subset)\n",
    "lr_val_score = lr_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "print(f\"Validation score for LR: {lr_val_score:.2f}\")\n",
    "\n",
    "\n",
    "# 4. Random Forest\n",
    "rf_model = RandomForestClassifier(bootstrap=False, max_depth=64, max_features='sqrt',\n",
    "                                  min_samples_leaf=3, min_samples_split=6, n_estimators=307)\n",
    "rf_model.fit(X_subset, y_subset)\n",
    "rf_val_score = rf_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "print(f\"Validation score for RandomForest: {rf_val_score:.2f}\")\n",
    "\n",
    "\n",
    "# 5. Balanced Random Forest\n",
    "brf_model = BalancedRandomForestClassifier(bootstrap=False, max_depth=23, max_features='sqrt',\n",
    "                                           min_samples_leaf=8, min_samples_split=17, n_estimators=237)\n",
    "brf_model.fit(X_subset, y_subset)\n",
    "brf_val_score = brf_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "print(f\"Validation score for Balanced Random Forest: {brf_val_score:.2f}\")\n",
    "\n",
    "\n",
    "# 6. RUSBoostClassifier\n",
    "rus_model = RUSBoostClassifier(learning_rate=0.1, n_estimators=150)\n",
    "rus_model.fit(X_subset, y_subset)\n",
    "rus_val_score = rus_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "print(f\"Validation score for RUSBoostClassifier: {rus_val_score:.2f}\")\n",
    "\n",
    "\n",
    "# 7. KNN\n",
    "knn_model = neighbors.KNeighborsClassifier(n_neighbors=12, weights='distance')\n",
    "knn_model.fit(X_subset, y_subset)\n",
    "knn_val_score = knn_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "print(f\"Validation score for KNN: {knn_val_score:.2f}\")\n",
    "\n",
    "\n",
    "# 8. Gaussian Process\n",
    "# kernel = 1**2 * RBF(length_scale=1)\n",
    "# gp_model = GaussianProcessClassifier(kernel=kernel)\n",
    "# gp_model.fit(X_subset, y_subset)\n",
    "# gp_val_score = gp_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "# print(f\"Validation score for GP: {gp_val_score:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "# 9. Neural Network\n",
    "nn_model = MLPClassifier(activation='relu', alpha=0.07653614103176526, early_stopping=True,\n",
    "                         hidden_layer_sizes=(229, 255, 168), learning_rate='adaptive',\n",
    "                         max_iter=11805, solver='adam', validation_fraction=0.1)\n",
    "nn_model.fit(X_subset, y_subset)\n",
    "nn_val_score = nn_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "print(f\"Validation score for NN: {nn_val_score:.2f}\")\n",
    "\n",
    "\n",
    "# 10. XGBoost\n",
    "xgb_model = xgb.XGBClassifier(colsample_bytree=0.6154469128110744, gamma=0.48205093205202343,\n",
    "                              learning_rate=0.3516317594127291, max_depth=44,\n",
    "                              min_child_weight=8, n_estimators=480, subsample=0.5866823267538861) #objective='multiclass', metric='multi_logloss',\n",
    "xgb_model.fit(X_subset, y_subset)\n",
    "xgb_val_score = xgb_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "print(f\"Validation score for XGBoost: {xgb_val_score:.2f}\")\n",
    "\n",
    "\n",
    "# 11. LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(colsample_bytree=0.7956488938538635, learning_rate=0.1473608964950321,\n",
    "                               max_depth=35, min_child_weight=1, n_estimators=276, num_leaves=120,\n",
    "                               reg_alpha=1.9434241907782075, reg_lambda=1.6978276485321677, subsample=0.8608647605824367) #objective='multiclass', metric='multi_logloss',\n",
    "lgb_model.fit(X_subset, y_subset)\n",
    "lgb_val_score = lgb_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "print(f\"Validation score for LightGBM: {lgb_val_score:.2f}\")\n",
    "\n",
    "\n",
    "# 12. SVM\n",
    "svm_model = SVC(C=524.8564316322379, degree=9, gamma=0.029222914019804192, kernel='rbf')\n",
    "svm_model.fit(X_subset, y_subset)\n",
    "svm_val_score = svm_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "print(f\"Validation score for SVM: {svm_val_score:.2f}\")\n",
    "\n",
    "\n",
    "# 13. Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(learning_rate=0.2259725093210579, max_depth=49,\n",
    "                                      min_samples_leaf=10, min_samples_split=17,\n",
    "                                      n_estimators=271, n_iter_no_change=10, subsample=0.728034992108518, tol=0.0001)\n",
    "gb_model.fit(X_subset, y_subset)\n",
    "gb_val_score = gb_model.score(X_all_val_transformed, Y_val_encoded)\n",
    "print(f\"Validation score for GB: {gb_val_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12823ad-4eed-4945-abec-0119c0c50894",
   "metadata": {},
   "source": [
    "## Performance analysis on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd0a23e-faf8-4113-a5bf-812c38a23f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_mean_list = []\n",
    "accuracy_std_list = []\n",
    "\n",
    "auc_mean_list = []\n",
    "auc_std_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31213430-8bdd-48b8-b01a-24517324d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_categorical_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f6cdb-bc81-4245-b74b-1fcca0d5c5c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate over implemented models\n",
    "for modeltoggle in [\"KNN\", \"DT\", \"LR\", \"RF\", \"BalancedRandomForest\", \"RUSBoostClassifier\", \"AdaBoost\", \"NN\", \"XGBoost\", \"SVM\", \"GB\", \"LightGBM\"]:\n",
    "\n",
    "\n",
    "    title = \"Defect Prediction \"\n",
    "    labels_categorical_=(le.classes_).tolist() #['Defect-free', 'Keyhole pores', 'Laser defocus', 'Laser-off']\n",
    "    n_classes = len(labels_categorical_)\n",
    "    X = X_all_test_transformed\n",
    "    Y = Y_test_encoded\n",
    "\n",
    "    # One-hot-encode the ouput\n",
    "    Y_test_ohe = label_binarize(Y_test, classes= labels_categorical_)\n",
    "\n",
    "    if modeltoggle == 'KNN':\n",
    "        model = knn_model\n",
    "    elif modeltoggle == 'DT':\n",
    "        model = dt_model\n",
    "    elif modeltoggle == 'LR':\n",
    "        model = lr_model\n",
    "    elif modeltoggle == 'RF':\n",
    "        model = rf_model\n",
    "    elif modeltoggle == 'BalancedRandomForest':\n",
    "        model = brf_model\n",
    "    elif modeltoggle == 'RUSBoostClassifier':\n",
    "        model = rus_model\n",
    "    elif modeltoggle == 'AdaBoost':\n",
    "        model = ada_model\n",
    "    elif modeltoggle == 'GP':\n",
    "        model = gp_model\n",
    "    elif modeltoggle == 'NN':\n",
    "        model = nn_model\n",
    "    elif modeltoggle == 'XGBoost':\n",
    "        model = xgb_model\n",
    "    elif modeltoggle == 'SVM':\n",
    "        model = svm_model\n",
    "    elif modeltoggle == 'GB':\n",
    "        model = gb_model\n",
    "    elif modeltoggle == 'LightGBM':\n",
    "        model = lgb_model\n",
    "\n",
    "    ################--------------------------------- confusion matrix ------------------#####################\n",
    "    ################---------------------------------------------------------------------#####################\n",
    "    # for calculating the confusion matrix\n",
    "    Y_predict = model.predict(X)\n",
    "    # Category/ label that was wrongly classified by the model: View the class with WRONG classificaiton \n",
    "    pred_result = list(zip(Y, Y_predict))\n",
    "    result_df = pd.DataFrame(pred_result, columns = ['label', 'pred_label'])\n",
    "    result_df = result_df[result_df['label'] != result_df['pred_label']]\n",
    "    print(classification_report(Y, Y_predict))\n",
    "    \n",
    "    conf_matrix(Y, Y_predict, classes=labels_categorical_)\n",
    "    save_fig(\"confusion_\"+ modeltoggle + \"_\" + \"ALL\")\n",
    "    \n",
    "    \n",
    "    ################------------ Testing performance on k-fold on the model -------------#####################\n",
    "    ################---------------------------------------------------------------------#####################\n",
    "    kf = KFold(n_splits=5)\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    trains = []\n",
    "    tests = []\n",
    "    \n",
    "    # for train, test in kf.split(X):\n",
    "    for train, test in skf.split(X, Y):\n",
    "\n",
    "        X_shuffle, y_shuffle = shuffle(X, Y, random_state=0)\n",
    "        y_shuffle = np.array(y_shuffle)\n",
    "\n",
    "        # X_cv_train_before = X_shuffle[train]\n",
    "        # X_cv_test_before = X_shuffle[test]\n",
    "        X_train_cv = X_shuffle[train]\n",
    "        X_test_cv = X_shuffle[test]\n",
    "        y_train_cv = y_shuffle[train]\n",
    "        y_test_cv = y_shuffle[test]\n",
    "        # clf.fit(X_train_cv, y_train_cv)\n",
    "        # trains.append(clf.score(X_train_cv, y_train_cv))\n",
    "        tests.append(model.score(X_test_cv, y_test_cv))\n",
    "    \n",
    "\n",
    "    ################--------------- AUC-ROC score measurement --------------------#####################\n",
    "\n",
    "    # ----------------Learn to predict each class against the other------------------------\n",
    "    # classifier = OneVsRestClassifier(model)\n",
    "    if modeltoggle == 'SVM':\n",
    "        # y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "        y_score = model.decision_function(X)\n",
    "    else:\n",
    "        # y_score = classifier.fit(X_train, Y_train_ohe).predict_proba(X_test)\n",
    "        y_score = model.predict_proba(X)\n",
    "    \n",
    "    # ---------------Compute ROC curve and ROC area for each class-------------------------\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(Y_test_ohe[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test_ohe.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # ----------------------------------Plot all ROC curves-------------------------------\n",
    "    plt.figure(figsize = (4,3), dpi = 300)\n",
    "    widths = 2\n",
    "    ax = gca()\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(widths)\n",
    "\n",
    "        tick_width = 1.5\n",
    "    plt.tick_params(direction = 'in', width = tick_width)\n",
    "    \n",
    "         \n",
    "    #---------------------------(1) micro and macro ROC curve---------------------------\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label=modeltoggle + ' - micro-average ROC curve (AUC = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='red', linestyle=':', linewidth=2, alpha = 0.8) #deeppink, midnightblue\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label=modeltoggle + ' - macro-average ROC curve (AUC = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=2, alpha = 0.8) #navy, gold\n",
    "    \n",
    "    #---------------------------(2) ROC curve for each class---------------------------\n",
    "    colors = cycle([\"aqua\", \"darkblue\", \"darkorange\", \"red\", 'green', 'silver', 'yellow', 'olive'])\n",
    "    # colors = cycle(['0.45', 'steelblue',  'olive', 'silver'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i],tpr[i],color=color,\n",
    "                 lw=1, alpha = 0.8,\n",
    "                 label=modeltoggle + \" ROC curve of class \\\"{0}\\\" (area = {1:0.2f})\".format(labels_categorical_[i], roc_auc[i])) \n",
    "        \n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=2)\n",
    "    plt.xlim([-0.02, 1.02])\n",
    "    plt.ylim([-0.02, 1.02])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    # plt.title(\"ROC curve\")\n",
    "    plt.legend(loc=\"lower right\",  fontsize = '6', frameon = True, framealpha=0.8)\n",
    "    # plt.show()\n",
    "    plt.grid(linestyle='--', alpha=0.5, linewidth=0.8)\n",
    "    \n",
    "    #---------------------------------Aggregate information----------------------------------\n",
    "    tests = np.array(tests)\n",
    "\n",
    "    test_accuracy_mean = tests.mean()\n",
    "    test_accuracy_std = tests.std()\n",
    "    \n",
    "    auc_score_list = []\n",
    "    auc_score_list.append(auc(fpr[\"micro\"], tpr[\"micro\"]))\n",
    "    \n",
    "    auc_score_array = np.array(auc_score_list)\n",
    "    auc_mean = auc_score_array.mean()\n",
    "    auc_std = auc_score_array.std()\n",
    "    \n",
    "    \n",
    "    # store into list\n",
    "    auc_mean_list.append(auc_mean)\n",
    "    auc_std_list.append(auc_std)\n",
    "    accuracy_mean_list.append(test_accuracy_mean)\n",
    "    accuracy_std_list.append(test_accuracy_std)\n",
    "    \n",
    "    print('Test Accuracy (cross-validation) for' , modeltoggle, '= {:.5f} ± {:.5f}'.format(test_accuracy_mean, test_accuracy_std))\n",
    "    print('micro-averaging AUC for' , modeltoggle, '= {:.5f} ± {:.5f}'.format(auc_mean, auc_std))\n",
    "    save_fig(\"ROC_\" + modeltoggle + \"_\" + \"audio_visual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0775b3a-6d65-4fa7-a459-af4286c1679a",
   "metadata": {},
   "source": [
    "## Save trained model into folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf88044-4762-4b3a-8d84-1560dd6a0a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "import joblib\n",
    "\n",
    "KNN_file = os.path.join(model_path, 'KNN.joblib')\n",
    "DT_file = os.path.join(model_path, 'DT.joblib')\n",
    "AdaBoost_file = os.path.join(model_path, 'AdaBoost.joblib')\n",
    "RF_file = os.path.join(model_path, 'RF.joblib')\n",
    "BalancedRandomForest_file = os.path.join(model_path, 'BalancedRandomForest.joblib')\n",
    "LightGBM_file = os.path.join(model_path, 'LightGBM.joblib')\n",
    "XGBoost_file = os.path.join(model_path, 'XGBoost.joblib')\n",
    "LR_file = os.path.join(model_path, 'LR.joblib')\n",
    "SVM_file = os.path.join(model_path, 'SVM.joblib')\n",
    "GB_file = os.path.join(model_path, 'GB.joblib')\n",
    "RUSBoostClassifier_file = os.path.join(model_path, 'RUSBoostClassifier.joblib')\n",
    "NN_file = os.path.join(model_path, 'NN.joblib')\n",
    "\n",
    "# Define the paths\n",
    "paths = {\n",
    "    'KNN': KNN_file,\n",
    "    'DT': DT_file,\n",
    "    'AdaBoost': AdaBoost_file,\n",
    "    'RF': RF_file,\n",
    "    'BalancedRandomForest': BalancedRandomForest_file,\n",
    "    'LightGBM': LightGBM_file,\n",
    "    'XGBoost': XGBoost_file,\n",
    "    'LR': LR_file,\n",
    "    'SVM': SVM_file,\n",
    "    'GB': GB_file,\n",
    "    'RUSBoostClassifier': RUSBoostClassifier_file,\n",
    "    # 'GP': GP_file, \n",
    "    'NN': NN_file\n",
    "}\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'KNN': knn_model,\n",
    "    'DT': dt_model,\n",
    "    'AdaBoost': ada_model,\n",
    "    'RF': rf_model,\n",
    "    'BalancedRandomForest': brf_model,\n",
    "    'LightGBM': lgb_model,\n",
    "    'XGBoost': xgb_model,\n",
    "    'LR': lr_model,\n",
    "    'SVM': svm_model,  \n",
    "    'GB': gb_model,  \n",
    "    'RUSBoostClassifier': rus_model,\n",
    "    # 'GP': gp_model,  \n",
    "    'NN': nn_model  \n",
    "}\n",
    "\n",
    "# Save models\n",
    "for name, model in models.items():\n",
    "    dump(model, paths[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b6951-3293-48e9-adcb-8db8b7cab603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = joblib.load(open(RF_file, 'rb'))\n",
    "result = loaded_model.score(X_all_test_transformed, Y_test_encoded)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a882eb-3cbc-4403-9d4d-1ca9e7565e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_sizes(paths, fontsize=14):\n",
    "    model_sizes = {}\n",
    "    for name, path in paths.items():\n",
    "        model_sizes[name] = os.path.getsize(path) // 1024  # Size in KB\n",
    "\n",
    "    sorted_model_sizes = {k: v for k, v in sorted(model_sizes.items(), key=lambda item: item[1])}\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(list(sorted_model_sizes.keys()), list(sorted_model_sizes.values()), \n",
    "             color='skyblue', edgecolor='black', linewidth=0.5)\n",
    "    plt.xlabel('Model Size (KB)', fontsize=fontsize+6, labelpad=10)\n",
    "    plt.ylabel('Model', fontsize=fontsize+6)\n",
    "    plt.xticks(fontsize=fontsize, rotation=45, ha='right')\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    plt.grid(which='both', linestyle='--', linewidth=0.5)\n",
    "    # plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_model_sizes(paths)\n",
    "save_fig(\"model size comparisons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992ebed5-66ad-487b-856f-4a55bf30ac55",
   "metadata": {},
   "source": [
    "## Model performance statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9682fd46-2712-4d1a-9d12-d5053b662b9a",
   "metadata": {},
   "source": [
    "BalancedRandomForest_fileTo evaluate the effectiveness of the classification model, metrics used to assess are:\n",
    "\n",
    "1. **$Precision = TP/(FP+TP)$**\n",
    "\n",
    "**Precision** provides the *positive predictive value, the proportion of samples that belong in category $x$ that are correctly placed in category $x$*. Example, among all predicted defect, how many did I predict correctly? High precision is with low FP (predict to be cracks but actually is not).\n",
    "\n",
    "2. **$f1 = 2*(Precision*Recall)/(Precision + Recall)$**\n",
    "\n",
    "**Weighted average for precision and recall**. This score takes both FN and FP into account as $Recall = TP/(FN+TP)$. This is better metric for evaluating an uneven class distribution problem, which is the case in this project. \n",
    "\n",
    "3. $Accuracy = (TP+TN)/(All predict)$\n",
    "\n",
    "Model achieve pretty high **>80%** overall accuracy.\n",
    "\n",
    "The model able to classify well for defects sounds. However, it did badly on the detecting ***cracks***\n",
    "\n",
    "- In conclusion, the initial model without Hyper-parameter tuning did pretty well in general. But it does not outperform the traditional ML algorithms. And it did poorly in classifying the cracking regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21018b7-ab0e-4752-93b8-851d82e3de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\"KNN\", \"DT\", \"LR\", \"RF\", \"BalancedRandomForest\", \"RUSBoostClassifier\", \"AdaBoost\", \"NN\", \"XGBoost\", \"SVM\", \"GB\", \"LightGBM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee6e73-2732-4767-a657-d03cc6df5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_mean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c1cbc-ea28-4967-8f0a-09fbaeaf44da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_model_metrics(models, mean_list, std_list, metric_name, color, \n",
    "                       bar_width=0.6, edge_width=1, fontsize=15, \n",
    "                       labelpad=10, figsize=(10, 8), dpi=300, add_baseline=False):\n",
    "    \n",
    "    # If baseline model is to be added (only for accuracy)\n",
    "    if add_baseline:\n",
    "        models.append(\"baseline model\")\n",
    "        mean_list.append(0.26)\n",
    "        std_list.append(0)\n",
    "    \n",
    "    # Sorting by mean values\n",
    "    sorted_indices = np.argsort(mean_list)\n",
    "    sorted_models = np.array(models)[sorted_indices]\n",
    "    sorted_means = np.array(mean_list)[sorted_indices]\n",
    "    sorted_stds = np.array(std_list)[sorted_indices]\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=figsize, dpi=dpi)\n",
    "    plt.bar(sorted_models, sorted_means, yerr=sorted_stds, \n",
    "            capsize=10, color=color, width=bar_width, \n",
    "            edgecolor='black', linewidth=edge_width)\n",
    "    \n",
    "    plt.ylabel(metric_name, fontsize=fontsize, labelpad=labelpad)\n",
    "    plt.title(f'Model {metric_name} Comparison', fontsize=fontsize)\n",
    "    \n",
    "    plt.xticks(fontsize=fontsize, rotation=45,  ha='right')\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    plt.xlabel(\"Models\", fontsize=fontsize, labelpad=labelpad)\n",
    "    \n",
    "    # Add dotted grid\n",
    "    plt.grid(which='both', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Show ticks outwards\n",
    "    plt.tick_params(direction='out', length=6, width=2, colors='black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylim([0, 1.02])\n",
    "    plt.yticks([0.0, 0.2, 0.4, 0.6, 0.8, 0.9, 1.0])\n",
    "    # plt.show()\n",
    "\n",
    "# Plotting Accuracy with improvements\n",
    "plot_model_metrics(models_list.copy(), accuracy_mean_list.copy(), accuracy_std_list.copy(), \n",
    "                   \"Accuracy\", 'skyblue', add_baseline=False)\n",
    "save_fig (\"Accuracy-all(audio_visual)\")\n",
    "# Plotting AUC with improvements\n",
    "plot_model_metrics(models_list.copy(), auc_mean_list.copy(), auc_std_list.copy(), \n",
    "                   \"AUC Score\", 'lightcoral')\n",
    "save_fig (\"AUC-all(audio_visual)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f75200-5104-4ee5-84a7-133cafa104c9",
   "metadata": {},
   "source": [
    "## Analyze the inference time\n",
    "\n",
    "1. Warm-Up Runs: A few 'warm-up' runs are often performed before the timing measurements to ensure that any lazy loading, caching, or other one-time operations have been completed.\n",
    "\n",
    "2. High-Resolution Timers: High-resolution timers (such as Python's time.perf_counter() or C++'s std::chrono) are used to measure the time elapsed.\n",
    "\n",
    "3. Excluding Data Loading: The time taken for just the model to make a prediction is measured, excluding any data loading or pre-processing time unless that is also a part of what is being evaluated.\n",
    "\n",
    "4. GPU/CPU Synchronization: If using a GPU, it's important to make sure to synchronize the CPU and GPU computations to accurately measure the time taken.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e08f45f-257f-4a92-b9f9-b1e988751ec1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "X_sample = X_all_test_transformed[10].reshape(1, -1)\n",
    "\n",
    "# Dictionary to store inference times\n",
    "inference_times = {}\n",
    "\n",
    "# Number of runs\n",
    "n_runs = 50\n",
    "\n",
    "# Loop through all models and measure inference time\n",
    "for model_name, model in models.items():\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        start_time = time.perf_counter()\n",
    "        predictions = model.predict(X_sample)\n",
    "        end_time = time.perf_counter()\n",
    "        times.append(end_time - start_time)\n",
    "        \n",
    "    # Calculate average and standard deviation\n",
    "    avg_time = sum(times) / n_runs\n",
    "    std_time = (sum((x - avg_time) ** 2 for x in times) / n_runs) ** 0.5\n",
    "    \n",
    "    inference_times[model_name] = (avg_time, std_time)\n",
    "    print(f\"Inference time for {model_name}: {avg_time:.6f} ± {std_time:.6f} seconds\")\n",
    "\n",
    "# Optional: Sort by average inference time\n",
    "sorted_times = {k: v for k, v in sorted(inference_times.items(), key=lambda item: item[1][0])}\n",
    "print(\"\\nModels sorted by inference time:\", sorted_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab114e-bfa4-48d6-8ff5-316b1a548d74",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_inference_time(models, inference_times, figsize=(10, 8), dpi=300):\n",
    "    # Unpack times and standard deviations\n",
    "    model_names = list(inference_times.keys())\n",
    "    avg_times = [x[0] * 1e3 for x in inference_times.values()]  # Convert to milliseconds\n",
    "    std_times = [x[1] * 1e3 for x in inference_times.values()]  # Convert to milliseconds\n",
    "    \n",
    "    # Sorting by mean values\n",
    "    sorted_indices = np.argsort(avg_times)\n",
    "    sorted_models = np.array(model_names)[sorted_indices]\n",
    "    sorted_means = np.array(avg_times)[sorted_indices]\n",
    "    sorted_stds = np.array(std_times)[sorted_indices]\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=figsize, dpi=dpi)\n",
    "\n",
    "    # Before plotting, adjust std deviation if it leads to negative values\n",
    "    corrected_stds = [min(std, mean) for std, mean in zip(sorted_stds, sorted_means)]\n",
    "    \n",
    "    plt.bar(sorted_models, sorted_means, yerr=corrected_stds, \n",
    "            capsize=10, color='skyblue', width=0.6, \n",
    "            edgecolor='black', linewidth=1)\n",
    "    \n",
    "    plt.ylabel('Inference Time (ms)', fontsize=15, labelpad=10)\n",
    "    plt.title('Model Inference Time Comparison', fontsize=15)\n",
    "    \n",
    "    plt.xticks(fontsize=15, rotation=45, ha='right')\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlabel(\"Models\", fontsize=15, labelpad=10)\n",
    "    \n",
    "    # Add dotted grid\n",
    "    plt.grid(which='both', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Show ticks outwards\n",
    "    plt.tick_params(direction='out', length=6, width=2, colors='black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "# Plot the inference times\n",
    "plot_inference_time(models, inference_times)\n",
    "save_fig(\"inference_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adae165-6b58-4faa-b30b-359f3e328b45",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the models \"AdaBoost\" and \"GB\"\n",
    "inference_times.pop(\"RF\", None)\n",
    "inference_times.pop(\"BalancedRandomForest\", None)\n",
    "inference_times.pop(\"RUSBoostClassifier\", None)\n",
    "inference_times.pop(\"AdaBoost\", None)\n",
    "inference_times.pop(\"KNN\", None)\n",
    "inference_times.pop(\"XGBoost\", None)\n",
    "# Extracting data for plotting\n",
    "model_names = list(inference_times.keys())\n",
    "\n",
    "plot_inference_time(model_names, inference_times)\n",
    "save_fig(\"inference_time_selected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
